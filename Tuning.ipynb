{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76abf9e0",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from timeit import timeit\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# NLTK Imports and Downloads\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60163c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f9e5c",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd14385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334910bc",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "Nulll values are generally not desireable in a dataset.  In certain cases, observations (rows) with low counts will simply be dropped, in other cases, they can be filled with other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7026a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NULL values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "df.drop(columns=['Unnamed: 0', 'longitude', 'latitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b353e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] =  pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a510a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'text_len' that counts the length for the derived field\n",
    "df['text_len'] = df.apply(lambda row: len(row['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452891b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for positive or negative\n",
    "df['target'] = df['stars_y'].apply(lambda c: 0 if c < 4 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c20eb",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "A common practice is to review any duplicates.  If there are large quantities, they can skew the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf976cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "len_after = df.shape[0]\n",
    "\n",
    "print(\"Before =\", len_before)\n",
    "# drop duplicates\n",
    "print(\"After =\", len_after)\n",
    "print('')\n",
    "print(\"Total Removed =\", len_before - len_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79284ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31430827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df = df[df['state'] != 'KS'].copy()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9174a1",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad223fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(corr, cmap=\"Blues\", annot=True, square=False, ax=ax,  linewidth = 1)\n",
    "plt.title('Pearson Correlation of Features')\n",
    "plt.yticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62392d4c-a914-436a-a488-57c4b8e246f7",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "There are a few variables that are correlated to each other.  \n",
    " - `target` was created from `stars_y` and therefore shows a high positive correlation\n",
    " - `cool`, `useful` and `funny` are slightly correlated to each other.  This probably means that users to vote with one item, vote with others. \n",
    " - `stars_y` and `stars_x`also show some correlation.  This makes sense because `stars_x` is the mean of all `stars_y` ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61f23e",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "For **Parts** of our analysis, the text needs to have some basic transformation for our models to work properly.  These are as follows:\n",
    "\n",
    "1. **Lower**: Convert all characters to lowercase\n",
    "1. **Remove Punctuation**: In most cases, punctuation doesn't help NLP and ML models and can be removed.\n",
    "1. **Stop Word Removal**: Stop words generally don't add context to analysis (unless the length of the text is very short (`100` - `200` characters) and can be removed.\n",
    "1. **Lemmatization**: Words will be reduced to their *Lemma* or root.  This will greatly improve the accuracy of the analysis since words like `swimming` and `swimmer` will be reduced to `swim`.\n",
    "\n",
    "**Note**: The original text will be preserved for other analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b473db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text, stem=\"None\"):\n",
    "    \n",
    "    final_string = \"\"\n",
    "    \n",
    "    # Make lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "    useless_words = useless_words + ['.', ',', '!', \"'\"]\n",
    "    \n",
    "    # Remove stop words\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "    \n",
    "    # Remove numbers\n",
    "    text_filtered = [re.sub('\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "    \n",
    "    # Stem or Lemmatize\n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "    \n",
    "    for word in text_stemmed:\n",
    "        final_string += word + \" \"\n",
    "    \n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d944195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(lambda x: clean_string(x, stem='Stem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79953ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31feeb6c",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION/ MODELING \n",
    "\n",
    ">*In machine learning and statistics, feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction. Feature selection techniques are used for several reasons[11]:*\n",
    "\n",
    ">- *simplification of models to make them easier to interpret by researchers/users,*\n",
    ">- *shorter training times,*\n",
    ">- *to avoid the curse of dimensionality,*\n",
    ">- *enhanced generalization by reducing overfitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['categories', 'city', 'state', 'postal_code', 'is_open', 'text_len', 'useful', 'cool', 'funny', 'review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "catFeat = df[targets].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7470bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "catFeat['categories'] = le.fit_transform(catFeat['categories'].astype(str))\n",
    "catFeat['city'] = le.fit_transform(catFeat['city'].astype(str))\n",
    "catFeat['state'] = le.fit_transform(catFeat['state'].astype(str))\n",
    "catFeat['postal_code'] = le.fit_transform(catFeat['postal_code'].astype(str))\n",
    "\n",
    "catFeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 30% test and 70% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(catFeat, \n",
    "                                                    df['target'], \n",
    "                                                    test_size=0.3, random_state=0)\n",
    "\n",
    "# Create a random forest classifier for feature importance\n",
    "clf = RandomForestClassifier(random_state=42, n_jobs=6, class_weight='balanced')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "total_importance = 0\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(targets, clf.feature_importances_):\n",
    "    if feature[1] > .1:\n",
    "        print(feature)\n",
    "        total_importance += feature[1]\n",
    "        \n",
    "print('\\nCumulative Importance of Selected Features: ', total_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adac9a33",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Many algorithms support binary classification.  We will use two and compare the results to select the best model.\n",
    "\n",
    " - **Random Forest Classifier**:  This classifier tends to be very robust.  It was used in the feature selection model above and will be tested against the features it selected.  Due to the nature of running many decision trees, it can take a while to compute larger datasets.\n",
    " > *A Random Forest classifier is an ensemble learning method for classification, regression, and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees [4].*\n",
    " - **Logistic Regression**: The logistic model is a fast and robust model that tends to run fairly quickly on all types of models.\n",
    " > *The logistic model (or logit model) is used to model the probability of a certain class or event existing, such as pass/fail, win/lose, alive/dead, or healthy/sick. This can be extended to model several classes of events, such as determining whether an image contains a cat, dog, or lion. Each object is detected in the image would be assigned a probability between 0 and 1, with a sum of one [5].*\n",
    "\n",
    "To create our model, we will be mixing both text and numeric values.  There are multiple ways to accomplish this, but we will be using a `ColumnTransformer` in a Pipeline.\n",
    "\n",
    "**Imbalanced Data**  \n",
    "The number of negative reviews is far less than the number of positive reviews. This is known as Imbalanced Data.  When you have imbalanced data, the model will tend to bias to the value with more observations (positive).  To correct this, we can run a process known as SMOTE.  This process uses a nearest-neighbor approach for generating new minority class samples.  The method is applied only to the training data and then tested on the original, untouched test partition.  The method chosen here is first to oversample the minority class making it balanced, and then undersample it to reduce the size.  This helps bring balance without bloating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed this up, let's just take a random subset of the data\n",
    "# df = df.sample(n=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db77f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['categories', 'postal_code', 'text_len', 'review_count', 'text_clean']]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b91b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f00126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipe(clf, ngrams=(1,1)):\n",
    "    \n",
    "    # Each pipeline uses the same column transformer.  \n",
    "    column_trans = ColumnTransformer(\n",
    "        [('Text', TfidfVectorizer(stop_words='english', ngram_range=ngrams), 'text_clean'),\n",
    "         ('Categories', TfidfVectorizer(), 'categories'), \n",
    "         ('OHE', OneHotEncoder(dtype='int', handle_unknown='ignore'),['postal_code']),\n",
    "         ('Numbers', MinMaxScaler(), ['review_count', 'text_len'])],\n",
    "        remainder='drop') \n",
    "    \n",
    "    pipeline = Pipeline([('prep',column_trans),\n",
    "                         ('over', SMOTE(random_state=42)),\n",
    "                         ('under', RandomUnderSampler(random_state=42)),\n",
    "                         ('clf', clf)])\n",
    "     \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'RandForest' : RandomForestClassifier(random_state=42, n_estimators=50),\n",
    "          'LogReg' : LogisticRegression(random_state=42, max_iter=1000)\n",
    "          }\n",
    "\n",
    "for name, model, in models.items():\n",
    "    clf = model\n",
    "    pipeline = create_pipe(clf)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='f1_macro', cv=3, n_jobs=1, error_score='raise')\n",
    "    print(name, ': Mean f1 Macro: %.3f and Standard Deviation: (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5b9c9",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning\n",
    "\n",
    "> *In machine learning, a hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are derived via training.*\n",
    "\n",
    "<br>\n",
    "\n",
    "> *Hyperparameters can be classified as model hyperparameters, that cannot be inferred while fitting the machine to the training set because they refer to the model selection task, or algorithm hyperparameters, that in principle have no influence on the performance of the model but affect the speed and quality of the learning process. An example of a model hyperparameter is the topology and size of a neural network. Examples of algorithm hyperparameters are learning rate and mini-batch size. [9]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25920511",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'clf__solver' : ['newton-cg', 'lbfgs', 'sag', 'liblinear'],\n",
    "               'clf__C' : [.1, 1, 10, 100],\n",
    "               'prep__Text__ngram_range': [(1, 1), (2, 2), (1, 2)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "pipeline = create_pipe(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(pipeline, \n",
    "#                     parameters, \n",
    "#                     scoring='f1_macro', \n",
    "#                     cv=3).fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best cross-validation accuracy: {:.3f}\".format(grid.best_score_))\n",
    "# print(\"Test set score: {:.3f}\".format(grid.score(X_test, y_test))) \n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# log_C = grid.best_params_['clf__C']\n",
    "# log_solver = grid.best_params_['clf__solver']\n",
    "# log_ngram = grid.best_params_['prep__Text__ngram_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a706591",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_C = 100\n",
    "log_solver = 'newton-cg'\n",
    "log_ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f76ae",
   "metadata": {},
   "source": [
    "45m 51s\n",
    "\n",
    "```\n",
    "Best cross-validation accuracy: 0.867\n",
    "Test set score: 0.872\n",
    "Best parameters: {'clf__C': 100, 'clf__solver': 'newton-cg', 'prep__Text__ngram_range': (1, 2)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = HalvingGridSearchCV(pipeline, \n",
    "#                            parameters, \n",
    "#                            scoring='f1_macro', \n",
    "#                            cv=3).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"Best cross-validation accuracy: {:.3f}\".format(grid.best_score_))\n",
    "# print(\"Test set score: {:.3f}\".format(grid.score(X_test, y_test))) \n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# log_C_b = grid.best_params_['clf__C']\n",
    "# log_solver_b = grid.best_params_['clf__solver']\n",
    "# log_ngram_b = grid.best_params_['prep__Text__ngram_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16183cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_C_b = 100\n",
    "log_solver_b = 'sag'\n",
    "log_ngram_b = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dec445",
   "metadata": {},
   "source": [
    "7m 43s\n",
    "\n",
    "```\n",
    "Best cross-validation accuracy: 0.867\n",
    "Test set score: 0.872\n",
    "Best parameters: {'clf__C': 100, 'clf__solver': 'sag', 'prep__Text__ngram_range': (1, 2)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63791d6a",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "1. **C:** \n",
    ">*Regularization is applying a penalty to increasing the magnitude of parameter values in order to reduce overfitting. When you train a model such as a logistic regression model, you are choosing parameters that give you the best fit to the data. This means minimizing the error between what the model predicts for your dependent variable given your data compared to what your dependent variable actually is. [6]*\n",
    "1. **Solver:** \n",
    ">*LIBLINEAR is a simple package for solving large-scale regularized linear\n",
    "classification, regression and outlier detection.*\n",
    "1. **N-Grams:** \n",
    ">*A bigram or digram is a sequence of two adjacent elements from a string of tokens, which are typically letters, syllables, or words. A bigram is an n-gram for n=2. The frequency distribution of every bigram in a string is commonly used for simple statistical analysis of text in many applications, including in computational linguistics, cryptography, and speech recognition*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4074df1",
   "metadata": {},
   "source": [
    "# PERFORMANCE ASSESSMENT\n",
    "\n",
    "Now that we have a model selected based on the cross-validation above, we can optimize the `Hyper Parameters` associated with the algorithm.  This allows for optimal results, potentially over and above the default settings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e748a8",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_print(pipeline, name):\n",
    "    ''' take a supplied pipeline and run it against the train-test spit \n",
    "    and product scoring results.'''\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, \n",
    "                                            y_pred, \n",
    "                                            cmap=plt.cm.Blues)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.title(name)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name + '.png', dpi=300) \n",
    "    plt.show; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "pipeline = create_pipe(clf)\n",
    "fit_and_print(pipeline, 'hyper_defaults')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=log_C, solver=log_solver, random_state=42, max_iter=500)\n",
    "pipeline = create_pipe(clf, log_ngram)\n",
    "fit_and_print(pipeline, 'hyper_grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c38b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=log_C_b, solver=log_solver_b, random_state=42, max_iter=500)\n",
    "pipeline = create_pipe(clf, log_ngram_b)\n",
    "fit_and_print(pipeline, 'hyper_halving')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397a78c",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyperparameter-tuning-for-machine-learning-models-1b80d783b946"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
